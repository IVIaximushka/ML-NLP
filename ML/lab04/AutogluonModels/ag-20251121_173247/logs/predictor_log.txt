Beginning AutoGluon training...
AutoGluon will save models to 'c:\Users\DmitrievMS\PycharmProjects\pythonProject\ML-NLP\ML\lab04\AutogluonModels\ag-20251121_173247'
=================== System Info ===================
AutoGluon Version:  1.4.0
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          8
GPU Count:          0
Memory Avail:       4.06 GB / 15.77 GB (25.7%)
Disk Space Avail:   72.87 GB / 476.72 GB (15.3%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'verbosity': 2}

Inferred time series frequency: 'D'
Provided train_data has 1972 rows, 1 time series. Median time series length is 1972 (min=1972, max=1972). 

Provided data contains following columns:
	target: 'target'
	past_covariates:
		categorical:        []
		continuous (float): ['lag_1', 'lag_2', 'lag_3', 'lag_7', 'lag_14', 'lag_30', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MAE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-11-21 20:32:47
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos[bolt_small]', 'TemporalFusionTransformer']
Training timeseries model Naive. 
	-19.5714      = Validation score (-MAE)
	0.01    s     = Training runtime
	3.66    s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. 
	-21.2857      = Validation score (-MAE)
	0.01    s     = Training runtime
	3.11    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. 
	-13.1449      = Validation score (-MAE)
	1.36    s     = Training runtime
	0.05    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. 
	-11.9077      = Validation score (-MAE)
	0.87    s     = Training runtime
	0.07    s     = Validation (prediction) runtime
Training timeseries model ETS. 
	-13.6074      = Validation score (-MAE)
	0.01    s     = Training runtime
	4.42    s     = Validation (prediction) runtime
Training timeseries model Theta. 
	-16.7071      = Validation score (-MAE)
	0.01    s     = Training runtime
	3.93    s     = Validation (prediction) runtime
Training timeseries model Chronos[bolt_small]. 
	-9.6286       = Validation score (-MAE)
	0.01    s     = Training runtime
	2.93    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. 
	-8.3210       = Validation score (-MAE)
	315.02  s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-8.3210       = Validation score (-MAE)
	0.27    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos[bolt_small]', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 335.92 s
Best model: TemporalFusionTransformer
Best model score: -8.3210
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
No path specified. Models will be saved in: "AutogluonModels\ag-20251121_174615"
Beginning AutoGluon training...
AutoGluon will save models to 'c:\Users\DmitrievMS\PycharmProjects\pythonProject\ML-NLP\ML\lab04\AutogluonModels\ag-20251121_174615'
=================== System Info ===================
AutoGluon Version:  1.4.0
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          8
GPU Count:          0
Memory Avail:       3.87 GB / 15.77 GB (24.5%)
Disk Space Avail:   72.69 GB / 476.72 GB (15.2%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'verbosity': 2}

Inferred time series frequency: 'D'
Provided train_data has 1972 rows, 1 time series. Median time series length is 1972 (min=1972, max=1972). 

Provided data contains following columns:
	target: 'target'
	past_covariates:
		categorical:        []
		continuous (float): ['lag_1', 'lag_2', 'lag_3', 'lag_7', 'lag_14', 'lag_30', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MAE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-11-21 20:46:15
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos[bolt_small]', 'TemporalFusionTransformer']
Training timeseries model Naive. 
	-19.5714      = Validation score (-MAE)
	0.01    s     = Training runtime
	3.71    s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. 
	-21.2857      = Validation score (-MAE)
	0.01    s     = Training runtime
	3.22    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. 
	-13.1449      = Validation score (-MAE)
	2.12    s     = Training runtime
	0.07    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. 
	-11.9077      = Validation score (-MAE)
	1.70    s     = Training runtime
	0.08    s     = Validation (prediction) runtime
Training timeseries model ETS. 
	-13.6074      = Validation score (-MAE)
	0.02    s     = Training runtime
	7.77    s     = Validation (prediction) runtime
Training timeseries model Theta. 
	-16.7071      = Validation score (-MAE)
	0.03    s     = Training runtime
	6.82    s     = Validation (prediction) runtime
Training timeseries model Chronos[bolt_small]. 
	-9.6286       = Validation score (-MAE)
	0.02    s     = Training runtime
	2.47    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. 
	-8.3210       = Validation score (-MAE)
	335.39  s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-8.3210       = Validation score (-MAE)
	0.31    s     = Training runtime
	0.03    s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos[bolt_small]', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 363.95 s
Best model: TemporalFusionTransformer
Best model score: -8.3210
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
No path specified. Models will be saved in: "AutogluonModels\ag-20251121_181156"
Beginning AutoGluon training...
AutoGluon will save models to 'c:\Users\DmitrievMS\PycharmProjects\pythonProject\ML-NLP\ML\lab04\AutogluonModels\ag-20251121_181156'
=================== System Info ===================
AutoGluon Version:  1.4.0
Python Version:     3.11.9
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.19045
CPU Count:          8
GPU Count:          0
Memory Avail:       4.02 GB / 15.77 GB (25.5%)
Disk Space Avail:   72.66 GB / 476.72 GB (15.2%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 7,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'verbosity': 2}

Inferred time series frequency: 'D'
Provided train_data has 1972 rows, 1 time series. Median time series length is 1972 (min=1972, max=1972). 

Provided data contains following columns:
	target: 'target'
	past_covariates:
		categorical:        []
		continuous (float): ['lag_1', 'lag_2', 'lag_3', 'lag_7', 'lag_14', 'lag_30', ...]

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MAE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-11-21 21:11:56
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos[bolt_small]', 'TemporalFusionTransformer']
Training timeseries model Naive. 
	-19.5714      = Validation score (-MAE)
	0.01    s     = Training runtime
	4.04    s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. 
	-21.2857      = Validation score (-MAE)
	0.02    s     = Training runtime
	3.21    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. 
	-13.1449      = Validation score (-MAE)
	1.67    s     = Training runtime
	0.07    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. 
	-11.9077      = Validation score (-MAE)
	1.33    s     = Training runtime
	0.12    s     = Validation (prediction) runtime
Training timeseries model ETS. 
	-13.6074      = Validation score (-MAE)
	0.02    s     = Training runtime
	7.75    s     = Validation (prediction) runtime
Training timeseries model Theta. 
	-16.7071      = Validation score (-MAE)
	0.02    s     = Training runtime
	6.48    s     = Validation (prediction) runtime
Training timeseries model Chronos[bolt_small]. 
	-9.6286       = Validation score (-MAE)
	0.02    s     = Training runtime
	2.82    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. 
	-8.3210       = Validation score (-MAE)
	465.15  s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-8.3210       = Validation score (-MAE)
	0.43    s     = Training runtime
	0.02    s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'Chronos[bolt_small]', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 493.37 s
Best model: TemporalFusionTransformer
Best model score: -8.3210
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
