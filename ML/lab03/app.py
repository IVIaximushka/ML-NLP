import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import io
import warnings
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.api import ExponentialSmoothing
from prophet import Prophet
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from scipy.stats import boxcox, boxcox_normmax
from statsmodels.stats.diagnostic import acorr_ljungbox
import scipy.stats as stats

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="Time Series Forecast",
    page_icon="üìà",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title("üìà –ê–Ω–∞–ª–∏–∑ –∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤")
st.markdown("---")

def load_sample_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
    dates = pd.date_range('2020-01-01', '2024-01-01', freq='D')
    trend = np.linspace(100, 200, len(dates))
    seasonal = 10 * np.sin(2 * np.pi * np.arange(len(dates)) / 365)
    noise = np.random.normal(0, 5, len(dates))
    values = trend + seasonal + noise
    
    return pd.DataFrame({
        'Date': dates,
        'number_sold': values
    })

def handle_data_upload():
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤"""
    st.sidebar.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    
    uploaded_file = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV/Parquet —Ñ–∞–π–ª", 
        type=['csv', 'parquet'],
        help="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏ Date –∏ number_sold"
    )
    
    if uploaded_file is not None:
        try:
            # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
            if uploaded_file.name.endswith('.parquet'):
                df = pd.read_parquet(uploaded_file)
            else:
                df = pd.read_csv(uploaded_file)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            if 'Date' not in df.columns:
                st.error("‚ùå –§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'Date'")
                return None
                
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã
            df['Date'] = pd.to_datetime(df['Date'])
            df = df.set_index('Date').sort_index()
            
            st.sidebar.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(df)} —Å—Ç—Ä–æ–∫")
            return df
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
            return None
    else:
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        if st.sidebar.button("üé≤ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö"):
            df = load_sample_data()
            df['Date'] = pd.to_datetime(df['Date'])
            df = df.set_index('Date').sort_index()
            st.sidebar.success("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö")
            return df
    
    return None

def model_parameters_sidebar(df):
    """–ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å –≤—ã–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏"""
    st.sidebar.header("‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏")
    
    # –í—ã–±–æ—Ä —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    target_col = st.sidebar.selectbox(
        "–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è", 
        options=numeric_cols,
        index=0 if len(numeric_cols) > 0 else 0
    )
    
    # –í—ã–±–æ—Ä –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞
    horizon = st.sidebar.radio(
        "–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è", 
        [1, 7, 30], 
        horizontal=True,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"
    )
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    model_type = st.sidebar.selectbox(
        "–ú–æ–¥–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è",
        ["ARIMA", "SARIMA", "Prophet", "Exponential Smoothing", "Naive", "Seasonal Naive"],
        help="–í—ã–±–µ—Ä–∏—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"
    )
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–æ–¥–µ–ª–µ–π
    if model_type == "ARIMA":
        st.sidebar.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã ARIMA")
        col1, col2, col3 = st.sidebar.columns(3)
        with col1:
            p = st.number_input("p (AR)", 0, 5, 1)
        with col2:
            d = st.number_input("d (I)", 0, 2, 1)
        with col3:
            q = st.number_input("q (MA)", 0, 5, 1)
    
    elif model_type == "SARIMA":
        st.sidebar.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã SARIMA")
        col1, col2, col3, col4 = st.sidebar.columns(4)
        with col1:
            p = st.number_input("p", 0, 3, 1)
        with col2:
            d = st.number_input("d", 0, 2, 1)
        with col3:
            q = st.number_input("q", 0, 3, 1)
        with col4:
            s = st.number_input("s", 1, 365, 7)
    
    elif model_type == "Exponential Smoothing":
        st.sidebar.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è")
        trend_type = st.sidebar.selectbox("–¢—Ä–µ–Ω–¥", ["add", "mul", None])
        seasonal_type = st.sidebar.selectbox("–°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å", ["add", "mul", None])
        seasonal_periods = st.sidebar.number_input("–ü–µ—Ä–∏–æ–¥ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏", 1, 365, 7)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π
    st.sidebar.header("üîÑ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö")
    use_boxcox = st.sidebar.checkbox("–ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ë–æ–∫—Å–∞-–ö–æ–∫—Å–∞")
    lambda_val = None
    if use_boxcox:
        lambda_choice = st.sidebar.selectbox(
            "–ü–∞—Ä–∞–º–µ—Ç—Ä Œª", 
            ["auto", "0 (–ª–æ–≥–∞—Ä–∏—Ñ–º)", "0.5", "1 (–±–µ–∑ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è)"]
        )
        if lambda_choice == "auto":
            lambda_val = "auto"
        elif lambda_choice == "0 (–ª–æ–≥–∞—Ä–∏—Ñ–º)":
            lambda_val = 0
        elif lambda_choice == "0.5":
            lambda_val = 0.5
        else:
            lambda_val = 1
    
    return {
        'target_col': target_col,
        'horizon': horizon,
        'model_type': model_type,
        'use_boxcox': use_boxcox,
        'lambda_val': lambda_val,
        'p': p if 'p' in locals() else 1,
        'd': d if 'd' in locals() else 1,
        'q': q if 'q' in locals() else 1,
        's': s if 's' in locals() else 7,
        'trend_type': trend_type if 'trend_type' in locals() else None,
        'seasonal_type': seasonal_type if 'seasonal_type' in locals() else None,
        'seasonal_periods': seasonal_periods if 'seasonal_periods' in locals() else 7
    }

def apply_transformations(data, use_boxcox, lambda_val):
    """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π –∫ –¥–∞–Ω–Ω—ã–º"""
    if not use_boxcox:
        return data, None, "–ë–µ–∑ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è"
    
    if lambda_val == "auto":
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä lambda
        lambda_opt = boxcox_normmax(data + 1)  # +1 —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        transformed_data = boxcox(data + 1, lmbda=lambda_opt)
        return transformed_data, lambda_opt, f"–ë–æ–∫—Å–∞-–ö–æ–∫—Å–∞ (Œª={lambda_opt:.3f})"
    else:
        # –†—É—á–Ω–æ–π –≤—ã–±–æ—Ä lambda
        if lambda_val == 0:
            transformed_data = np.log(data + 1)
            return transformed_data, 0, "–õ–æ–≥–∞—Ä–∏—Ñ–º"
        else:
            transformed_data = data ** lambda_val
            return transformed_data, lambda_val, f"–°—Ç–µ–ø–µ–Ω–Ω–æ–µ (Œª={lambda_val})"

def inverse_transformations(data, lambda_val, transformation_type):
    """–û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
    if transformation_type == "–õ–æ–≥–∞—Ä–∏—Ñ–º":
        return np.exp(data) - 1
    elif "–ë–æ–∫—Å–∞-–ö–æ–∫—Å–∞" in transformation_type:
        # –î–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        return data
    elif "–°—Ç–µ–ø–µ–Ω–Ω–æ–µ" in transformation_type:
        return data ** (1/lambda_val)
    else:
        return data

def train_arima_model(data, order, horizon):
    """–û–±—É—á–µ–Ω–∏–µ ARIMA –º–æ–¥–µ–ª–∏"""
    try:
        model = ARIMA(data, order=order)
        fitted_model = model.fit()
        
        # –ü—Ä–æ–≥–Ω–æ–∑
        forecast_result = fitted_model.get_forecast(steps=horizon)
        forecast = forecast_result.predicted_mean
        ci = forecast_result.conf_int()
        
        return forecast, ci, fitted_model
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ ARIMA: {e}")
        return None, None, None

def train_sarima_model(data, order, seasonal_order, horizon):
    """–û–±—É—á–µ–Ω–∏–µ SARIMA –º–æ–¥–µ–ª–∏"""
    try:
        model = SARIMAX(data, order=order, seasonal_order=seasonal_order)
        fitted_model = model.fit(disp=False)
        
        # –ü—Ä–æ–≥–Ω–æ–∑
        forecast_result = fitted_model.get_forecast(steps=horizon)
        forecast = forecast_result.predicted_mean
        ci = forecast_result.conf_int()
        
        return forecast, ci, fitted_model
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ SARIMA: {e}")
        return None, None, None

def train_prophet_model(data, horizon):
    """–û–±—É—á–µ–Ω–∏–µ Prophet –º–æ–¥–µ–ª–∏"""
    try:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Prophet
        prophet_df = data.reset_index()
        prophet_df.columns = ['ds', 'y']
        
        model = Prophet(
            yearly_seasonality=True,
            weekly_seasonality=True,
            daily_seasonality=False
        )
        model.fit(prophet_df)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –±—É–¥—É—â–∏—Ö –¥–∞—Ç
        future = model.make_future_dataframe(periods=horizon)
        forecast_df = model.predict(future)
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞
        forecast = forecast_df['yhat'].values[-horizon:]
        ci_lower = forecast_df['yhat_lower'].values[-horizon:]
        ci_upper = forecast_df['yhat_upper'].values[-horizon:]
        
        ci = pd.DataFrame({
            'lower': ci_lower,
            'upper': ci_upper
        })
        
        return forecast, ci, model
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ Prophet: {e}")
        return None, None, None

def train_exponential_smoothing(data, trend, seasonal, seasonal_periods, horizon):
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è"""
    try:
        model = ExponentialSmoothing(
            data,
            trend=trend,
            seasonal=seasonal,
            seasonal_periods=seasonal_periods
        )
        fitted_model = model.fit()
        
        # –ü—Ä–æ–≥–Ω–æ–∑
        forecast = fitted_model.forecast(horizon)
        
        return forecast, None, fitted_model
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ Exponential Smoothing: {e}")
        return None, None, None

def naive_forecast(data, horizon, seasonal_period=1):
    """–ù–∞–∏–≤–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑"""
    if seasonal_period > 1:
        # –°–µ–∑–æ–Ω–Ω—ã–π –Ω–∞–∏–≤–Ω—ã–π
        return np.tile(data[-seasonal_period:], int(np.ceil(horizon/seasonal_period)))[:horizon]
    else:
        # –ü—Ä–æ—Å—Ç–æ–π –Ω–∞–∏–≤–Ω—ã–π
        return np.full(horizon, data[-1])

def calculate_metrics(actual, forecast, model_name):
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞"""
    if len(actual) != len(forecast):
        min_len = min(len(actual), len(forecast))
        actual = actual[:min_len]
        forecast = forecast[:min_len]
    
    metrics = {}
    
    try:
        metrics['MAE'] = mean_absolute_error(actual, forecast)
        metrics['RMSE'] = np.sqrt(mean_squared_error(actual, forecast))
        metrics['MAPE'] = np.mean(np.abs((actual - forecast) / actual)) * 100
        metrics['R2'] = r2_score(actual, forecast)
        
        # MASE (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        naive_errors = np.mean(np.abs(np.diff(actual)))
        if naive_errors > 0:
            metrics['MASE'] = metrics['MAE'] / naive_errors
        else:
            metrics['MASE'] = np.nan
            
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫: {e}")
        
    return metrics

def plot_forecast_results(historical, forecast, ci_lower, ci_upper, model_name, transformation_info):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ —Å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏"""
    fig = go.Figure()
    
    # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
    fig.add_trace(go.Scatter(
        x=historical.index, y=historical.values,
        name='–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ',
        line=dict(color='blue', width=2),
        opacity=0.7
    ))
    
    # –ü—Ä–æ–≥–Ω–æ–∑
    forecast_dates = pd.date_range(
        start=historical.index[-1] + pd.Timedelta(days=1),
        periods=len(forecast),
        freq='D'
    )
    
    fig.add_trace(go.Scatter(
        x=forecast_dates, y=forecast,
        name=f'–ü—Ä–æ–≥–Ω–æ–∑ ({model_name})',
        line=dict(color='red', width=3, dash='dash')
    ))
    
    # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
    if ci_lower is not None and ci_upper is not None:
        fig.add_trace(go.Scatter(
            x=forecast_dates, y=ci_upper,
            name='–í–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ –î–ò',
            line=dict(color='lightgray', width=1),
            showlegend=False
        ))
        fig.add_trace(go.Scatter(
            x=forecast_dates, y=ci_lower,
            name='–ù–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ –î–ò',
            fill='tonexty',
            fillcolor='rgba(211,211,211,0.3)',
            line=dict(color='lightgray', width=1),
            showlegend=False
        ))
    
    fig.update_layout(
        title=f"–ü—Ä–æ–≥–Ω–æ–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ - {model_name} ({transformation_info})",
        xaxis_title="–î–∞—Ç–∞",
        yaxis_title="–ó–Ω–∞—á–µ–Ω–∏–µ",
        hovermode="x unified",
        height=500
    )
    
    return fig

def plot_residuals_analysis(model, model_name, data, forecast):
    """–ê–Ω–∞–ª–∏–∑ –æ—Å—Ç–∞—Ç–∫–æ–≤ –º–æ–¥–µ–ª–∏"""
    if model is None:
        return None
        
    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤
        if hasattr(model, 'resid'):
            residuals = model.resid.dropna()
        else:
            # –î–ª—è –º–æ–¥–µ–ª–µ–π –±–µ–∑ –∞—Ç—Ä–∏–±—É—Ç–∞ resid
            residuals = data - forecast
        
        if len(residuals) < 5:
            return None
            
        # –°–æ–∑–¥–∞–Ω–∏–µ subplots
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤', 'Q-Q plot', 
                          'ACF –æ—Å—Ç–∞—Ç–∫–æ–≤', '–û—Å—Ç–∞—Ç–∫–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏')
        )
        
        # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤
        fig.add_trace(go.Histogram(x=residuals, nbinsx=30, name="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ"),
                     row=1, col=1)
        
        # Q-Q plot
        qq_data = stats.probplot(residuals, dist="norm")
        fig.add_trace(go.Scatter(x=qq_data[0][0], y=qq_data[0][1], 
                               mode='markers', name="Q-Q"),
                     row=1, col=2)
        fig.add_trace(go.Scatter(x=qq_data[0][0], y=qq_data[0][0]*qq_data[1][0] + qq_data[1][1],
                               mode='lines', name="–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ"),
                     row=1, col=2)
        
        # ACF –æ—Å—Ç–∞—Ç–∫–æ–≤
        acf_values = acf(residuals, nlags=20)
        fig.add_trace(go.Bar(x=list(range(len(acf_values))), y=acf_values,
                           name="ACF"),
                     row=2, col=1)
        
        # –û—Å—Ç–∞—Ç–∫–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏
        fig.add_trace(go.Scatter(x=data.index[-len(residuals):], y=residuals,
                               mode='lines', name="–û—Å—Ç–∞—Ç–∫–∏"),
                     row=2, col=2)
        
        fig.update_layout(height=600, title_text=f"–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤ - {model_name}")
        return fig
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤: {e}")
        return None

def export_forecast(forecast, model_name, historical):
    """–≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –≤ —Ñ–∞–π–ª"""
    forecast_dates = pd.date_range(
        start=historical.index[-1] + pd.Timedelta(days=1),
        periods=len(forecast),
        freq='D'
    )
    
    forecast_df = pd.DataFrame({
        'Date': forecast_dates,
        'Forecast': forecast,
        'Model': model_name
    })
    
    csv = forecast_df.to_csv(index=False)
    
    st.download_button(
        label="üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ –≤ CSV",
        data=csv,
        file_name=f"forecast_{model_name}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.csv",
        mime="text/csv",
        use_container_width=True
    )

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = handle_data_upload()
    
    if df is None:
        # –ü–æ–∫–∞–∑ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
        st.markdown("""
        ## üöÄ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤!
        
        ### –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
        1. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ** —á–µ—Ä–µ–∑ –±–æ–∫–æ–≤—É—é –ø–∞–Ω–µ–ª—å —Å–ª–µ–≤–∞
        2. **–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã** –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
        3. **–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç** –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        4. **–ü–æ–ª—É—á–∏—Ç–µ –ø—Ä–æ–≥–Ω–æ–∑** –∏ –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞
        
        ### –§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö:
        - CSV –∏–ª–∏ Parquet —Ñ–∞–π–ª
        - –ö–æ–ª–æ–Ω–∫–∞ `Date` —Å –¥–∞—Ç–∞–º–∏
        - –ö–æ–ª–æ–Ω–∫–∞ —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        
        ### –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:
        - **ARIMA/SARIMA** - –¥–ª—è —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã—Ö —Ä—è–¥–æ–≤
        - **Prophet** - –¥–ª—è —Ä—è–¥–æ–≤ —Å —Ç—Ä–µ–Ω–¥–æ–º –∏ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å—é  
        - **Exponential Smoothing** - –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
        - **Naive –º–µ—Ç–æ–¥—ã** - –∫–∞–∫ –±–µ–Ω—á–º–∞—Ä–∫–∏
        
        –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É "üé≤ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö" —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å!
        """)
        return
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    params = model_parameters_sidebar(df)
    
    # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö")
        
        # –ì—Ä–∞—Ñ–∏–∫ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        fig_data = px.line(df, y=params['target_col'], 
                          title=f"–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {params['target_col']}")
        st.plotly_chart(fig_data, use_container_width=True)
    
    with col2:
        st.subheader("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
        st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π", len(df))
        st.metric("–ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö", 
                 f"{df.index.min().strftime('%Y-%m-%d')} - {df.index.max().strftime('%Y-%m-%d')}")
        st.metric("–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ", f"{df[params['target_col']].mean():.2f}")
        st.metric("–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ", f"{df[params['target_col']].std():.2f}")
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
    train_size = int(len(df) * 0.8)
    train_data = df[params['target_col']].iloc[:train_size]
    test_data = df[params['target_col']].iloc[train_size:train_size + params['horizon']]
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π
    transformed_data, lambda_val, transformation_info = apply_transformations(
        train_data, params['use_boxcox'], params['lambda_val']
    )
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    st.subheader("üéØ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ")
    
    forecast = None
    ci = None
    trained_model = None
    
    with st.spinner(f"–û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å {params['model_type']}..."):
        if params['model_type'] == "ARIMA":
            forecast, ci, trained_model = train_arima_model(
                transformed_data, 
                (params['p'], params['d'], params['q']), 
                params['horizon']
            )
        elif params['model_type'] == "SARIMA":
            forecast, ci, trained_model = train_sarima_model(
                transformed_data,
                (params['p'], params['d'], params['q']),
                (params['p'], params['d'], params['q'], params['s']),
                params['horizon']
            )
        elif params['model_type'] == "Prophet":
            forecast, ci, trained_model = train_prophet_model(
                transformed_data, 
                params['horizon']
            )
        elif params['model_type'] == "Exponential Smoothing":
            forecast, ci, trained_model = train_exponential_smoothing(
                transformed_data,
                params['trend_type'],
                params['seasonal_type'],
                params['seasonal_periods'],
                params['horizon']
            )
        elif params['model_type'] == "Naive":
            forecast = naive_forecast(transformed_data.values, params['horizon'])
        elif params['model_type'] == "Seasonal Naive":
            forecast = naive_forecast(transformed_data.values, params['horizon'], params['s'])
    
    if forecast is not None:
        # –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω—è–ª–æ—Å—å
        if params['use_boxcox']:
            forecast = inverse_transformations(forecast, lambda_val, transformation_info)
            if ci is not None:
                ci['lower'] = inverse_transformations(ci['lower'], lambda_val, transformation_info)
                ci['upper'] = inverse_transformations(ci['upper'], lambda_val, transformation_info)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        fig_forecast = plot_forecast_results(
            train_data, forecast, 
            ci['lower'] if ci is not None else None,
            ci['upper'] if ci is not None else None,
            params['model_type'], transformation_info
        )
        st.plotly_chart(fig_forecast, use_container_width=True)
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        if len(test_data) >= len(forecast):
            metrics = calculate_metrics(test_data.values[:len(forecast)], forecast, params['model_type'])
            
            st.subheader("üìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("MAE", f"{metrics.get('MAE', 0):.2f}")
            with col2:
                st.metric("RMSE", f"{metrics.get('RMSE', 0):.2f}")
            with col3:
                st.metric("MAPE", f"{metrics.get('MAPE', 0):.1f}%")
            with col4:
                st.metric("R¬≤", f"{metrics.get('R2', 0):.3f}")
        
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤
        if trained_model is not None:
            fig_residuals = plot_residuals_analysis(
                trained_model, params['model_type'], train_data, forecast
            )
            if fig_residuals:
                st.plotly_chart(fig_residuals, use_container_width=True)
        
        # –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        st.subheader("üíæ –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        export_forecast(forecast, params['model_type'], train_data)
        
    else:
        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏.")

if __name__ == "__main__":
    main()